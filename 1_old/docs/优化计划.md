# 优化计划

1. Q: 子节点就绪判断. 现在是 dag 执行时动态解析, 可以参考 spark stage 添加静态解析过程.
    1. A: 伪概念. spark.stage 是因为需要聚合到一个节点处理, 才进行了 stage 划分. 实际上, 每个 stage
        就类似于 dag 的一个节点. 而且, dag.node 还有优先级等概念, 执行方式也不同, 已经可以视为一个 stage 了.
2. node 优先级. 现在是静态解析, 但其实运行时因为 prune 等原因, 优先级是变化的, 可以动静结合判断.
3. 插件系统, 现在是用统一的函数签名 `func(ctx, args...)(map[string]interface{},error)`.
    这样导致插件内部每次都需要进行类型转换. 考虑下如果使用 `reflect.Method` 呢?
    目前实现参考 `supplier/plugin`


其他
1. Debug 模式完善
    1. *done* dag.view: 新增了 dag 层级展示, 界面展示.
    2. 流程中的 debug 信息展示. 可以看下 go 基础库是怎么做的.
2. 工作流模式由 `点, 边, 图` 构成, 点负责执行, 边负责节点间数据传递和依赖处理, 图负责调度节点.
    在 datasupply 中, 点被具象为 Node 结构体, 边具象为 Node.Param 以及由此构建的 nexts/prevs.
    节点类型和边类型也具象为补数所需的参数传递/结果赋值. 后续有需要可以按照工作流模式对 datasupply 进行扩展修改.


备注:
1. 只要 dag.Run 发挥 runtime, 则之前思考的 result_builder 的问题就全部解决了.
    1. dag.Run()->runtime, rt.WaitSyncDone 然后就可以上分布式锁, 然后因为 writer 也是自定义的, writer 也可以设置这个锁. 所有问题都解决了.
2. nodeRuntime 应该改为 node.newRuntime, 一是因为 runtime 应该依靠 node 存在, 这样写更合适. 二是风格更统一了.
3. 目前而言, 为了快速上线, 可以先保持这种方案, 直接取消同步异步区别, 所有字段成功后才返回.
